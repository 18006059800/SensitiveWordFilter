@startuml

abstract class AbstractList
abstract AbstractCollection
interface List
interface Collection

List <|-- AbstractList
Collection <|-- AbstractCollection

Collection <|- List
AbstractCollection <|- AbstractList
AbstractList <|-- ArrayList


class ArrayList {
Object[] elementData
size()
}

enum TimeUnit {
DAYS
HOURS
MINUTES
}

@enduml

@startuml

[基于规则机器学习]
[HDFS]
:业务员:

package "ElasticSearch" {
[update]
[analy]
[search]
}
package "MachineLearning" {
[SparkMlib]
[SparkStreaming]
}
[kafka:数据输入流] -[#00AA11]-> MachineLearning :敏感词热发现
MachineLearning -[#00AA11]-> [redis] : 新发现的敏感词存储到
[redis] -[#00AA11]-> [update] : 热词更新
MachineLearning -[#00AA11]-> [HDFS] : 将输入数据持久化

:业务员: --> ElasticSearch :定期检验敏感词库的准确性


[kafka:数据输入流] -[#0000FF]> analy : 实时文本处理
 analy -[#0000FF]->  基于规则机器学习 : 分词
 基于规则机器学习 <-[#0000FF]-> [search]
 基于规则机器学习  -[#0000FF]-> [kafka:输出流] : 非敏感词语句
 基于规则机器学习  -[#0000FF]-> [kafka:敏感语句流]: 敏感词语句


@enduml

@startuml
[kafka]
package "ElasticSearch" {
[analy]
[search]
[update]
}
package "MachineLearning" {
[SparkMlib]
[SparkStreaming]
}
[kafka]  -> MachineLearning :敏感词热发现
MachineLearning -> [redis] : 新发现的敏感词存储到
[redis] -> [update] : 热词更新

:业务员: --> ElasticSearch :定期检验敏感词库的准确性
@enduml


@startuml
==敏感词过滤阶段==
kafka -> storm : 实时获取流数据
storm -> elasticsearch : 通过Ik插件完成分词
elasticsearch -> 机器学习模块 : 分别索引各个分词是否是敏感词
机器学习模块-> 健康语句流: 可以正常显示的敏感语句流
机器学习模块-> 不健康语句流: 不可以正常显示的敏感语句流
 健康语句流 -> 第三方展示平台

==热词发现更新阶段==
kafka->sparkstreaming: 每隔指定时间段获取数据
机器学习模块 <- sparkstreaming: 每隔指定时间段获取数据
sparkstreaming -> sparkMlib :模型训练
sparkMlib -> redis :发现敏感词,更新
redis -> elasticsearch: 更新Es敏感词库,创建敏感词库索引

==业务人员干预阶段==
业务人员 -> elasticsearch : 检查敏感词的准确性，进行删除，增加，更新
业务人员 -> 健康语句流: 针对一些评论类操作,业务人员可以进行敏感词人工判断
业务人员 -> 不健康语句流: 针对一些评论类操作,业务人员可以进行敏感词人工判断
@enduml

