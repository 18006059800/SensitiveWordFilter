@startuml

abstract class AbstractList
abstract AbstractCollection
interface List
interface Collection

List <|-- AbstractList
Collection <|-- AbstractCollection

Collection <|- List
AbstractCollection <|- AbstractList
AbstractList <|-- ArrayList


class ArrayList {
Object[] elementData
size()
}

enum TimeUnit {
DAYS
HOURS
MINUTES
}

@enduml

@startuml

[基于规则机器学习]
[HDFS]
:业务员:

package "ElasticSearch" {
[update]
[analy]
[search]
}
package "MachineLearning" {
[SparkMlib]
[SparkStreaming]
}
[kafka:数据输入流] -[#00AA11]-> MachineLearning :敏感词热发现
MachineLearning -[#00AA11]-> [redis] : 新发现的敏感词存储到
[redis] -[#00AA11]-> [update] : 热词更新
MachineLearning -[#00AA11]-> [HDFS] : 将输入数据持久化

:业务员: --> ElasticSearch :定期检验敏感词库的准确性


[kafka:数据输入流] -[#0000FF]> analy : 实时文本处理
 analy -[#0000FF]->  基于规则机器学习 : 分词
 基于规则机器学习 <-[#0000FF]-> [search]
 基于规则机器学习  -[#0000FF]-> [kafka:输出流] : 语句进行敏感标记


@enduml

@startuml
[kafka]
package "ElasticSearch" {
[analy]
[search]
[update]
}
package "MachineLearning" {
[SparkMlib]
[SparkStreaming]
}
[kafka]  -> MachineLearning :敏感词热发现
MachineLearning -> [redis] : 新发现的敏感词存储到
[redis] -> [update] : 热词更新

:业务员: --> ElasticSearch :定期检验敏感词库的准确性
@enduml


@startuml
==敏感词过滤阶段==
kafka -> storm : 实时获取流数据
storm -> elasticsearch : 通过Ik插件完成分词
elasticsearch -> 机器学习模块 : 分别索引各个分词是否是敏感词
机器学习模块-> 含敏感性标记流: 可以正常显示的敏感语句流isSensitive=true
机器学习模块-> 含敏感性标记流: 不可以正常显示的敏感语句流isSensitive=false
含敏感性标记流 -> 第三方展示平台: 非敏感信息

==热词发现更新阶段==
kafka->sparkstreaming: 每隔指定时间段获取数据
机器学习模块 <- sparkstreaming: 每隔指定时间段获取数据
sparkstreaming -> sparkMlib :模型训练
sparkMlib -> redis :发现敏感词,更新
redis -> elasticsearch: 更新Es敏感词库,创建敏感词库索引

==业务人员干预阶段==
业务人员 -> elasticsearch : 检查敏感词的准确性，进行删除，增加，更新
业务人员 -> 含敏感性标记流: 针对一些评论类操作,业务人员可以进行敏感词人工判断
业务人员 -> 含敏感性标记流: 针对一些评论类操作,业务人员可以进行敏感词人工判断
@enduml


@startuml
package "定义输入输出流" {
[定义input_topic]
[定义output_topic]
[定义输入数据格式: 可选]
[队列应用名称 ]
[服务状态 : defined，active，stop]
}
 package "修改数据库" {
 [插入数据]
 }

 package "创建消息队列" {
[创建input_topic：3 分区2备份]
[创建output_topic：3 分区2备份]

 }

 package "启动过滤任务" {
 [启动storm程序]
 [启动machineLearn 程序]
 [配置前端监听队列]
 }

 package "停止过滤任务" {
 [停止storm程序]
 [停止machineLearn 程序]
 [配置前端监听队列]
 [修改数据库状态为stop]
 }

 定义输入输出流 -> 修改数据库 :数据入库
 修改数据库 -> 创建消息队列 : kafka 创建topic
 创建消息队列 -> 启动过滤任务: 启动敏感词过滤系统



@enduml
@startuml

定义输入输出流 -> 修改数据库 : 定义input_topic，output_topic，输入数据格式
修改数据库 -> 创建消息队列: 为input_topic，output_topic 在kafka上创建topic，每个topic 3分区2备份
创建消息队列 -> 启动过滤任务: 启动storm程序，mechine程序，前端监听配置
@enduml

@startuml
package "start"{
[启动StormKafkaFilter程序,开启敏感词敏感词]
[启动MLSensitiveWordStreaming程序，开启敏感词发现]
}
package "获取信息" {
[根据id 读取topic_manager_id中对应信息]
}
package "stop" {
[停止StormKafkaFilter程序,停止敏感词敏感词]
[停止MLSensitiveWordStreaming程序，停止敏感词发现]
}
[调用restful接口]-> 获取信息
获取信息->[根据status状态触发操作]
[根据status状态触发操作] -> start : status =start
[根据status状态触发操作] -> stop: status = start
[根据status状态触发操作] -> [暂不处理]: status = stop,status = define
@enduml

@startuml

调用restful接口 -> 获取信息 :根据id 读取topic_manager_id中对应信息
获取信息 -> 根据status状态触发操作: 解析statu状态
根据status状态触发操作 -> start: 启动StormKafkaFilter程序,开启敏感词敏感词
根据status状态触发操作 -> start: 启动MLSensitiveWordStreaming程序，开启敏感词发现

根据status状态触发操作 -> stop: 停止StormKafkaFilter程序,停止敏感词敏感词
根据status状态触发操作 -> stop: 停止MLSensitiveWordStreaming程序，停止敏感词发现

@enduml


@startuml

start -> 入库 : 修改status状态为status
入库 -> 调用restfulapi: 启动过滤,解析启动结果
入库 -> 启动多线程:根据主题的partition数量启动多线程
启动多线程 -> 消费数据: 消费主题"sensitive_filter_input_topic"信息
消费数据 -> 人工过滤:人工标注敏感词
人工过滤 -> 输出消息:输出消息到主题"sensitive__filter_output_topic"
输出消息 -> 启动多线程

@enduml

@startuml

stop -> 入库 : 修改status状态为stop
入库 -> 调用restfulapi接口: 启动过滤,解析启动结果
入库 -> 关闭多线程:关闭多线程停止人工过滤

@enduml